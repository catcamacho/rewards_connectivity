{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from os.path import join\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl.preprocess import FLIRT, SUSAN\n",
    "from nipype.interfaces.fsl.utils import Merge, ImageMeants\n",
    "from nipype.interfaces.fsl.model import GLM, Level1Design, FEATModel\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# Set study variables\n",
    "smoothing_kernel = 4\n",
    "\n",
    "analysis_home = '/Users/catcamacho/Box/LNCD_rewards_connectivity'\n",
    "#analysis_home = '/Volumes/Zeus/Cat'\n",
    "preproc_dir = analysis_home + '/subjs'\n",
    "raw_dir = analysis_home + '/subjs'\n",
    "#raw_dir = '/Volumes/Phillips/bars/APWF_bars/subjs'\n",
    "preproc_dir = analysis_home + '/proc/preprocessing'\n",
    "firstlevel_dir = analysis_home + '/proc/firstlevel'\n",
    "secondlevel_dir = analysis_home + '/proc/secondlevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "template_dir = analysis_home + '/templates'\n",
    "\n",
    "MNI_template = template_dir + '/MNI152_T1_2mm_brain.nii'\n",
    "#pull subject info to iter over\n",
    "#subject_info = DataFrame.from_csv(analysis_home + '/misc/subjs.csv')\n",
    "#subjects_list = subject_info['SubjID'].tolist()\n",
    "#timepoints = subject_info['Timepoint'].tolist()\n",
    "\n",
    "subjects_list = ['10766']\n",
    "timepoints = [1]\n",
    "\n",
    "# Seed locations and seed list\n",
    "seed_dir = analysis_home + '/seeds'\n",
    "L_amyg = seed_dir + '/L_amyg_anatomical.nii'\n",
    "R_amyg = seed_dir + '/R_amyg_anatomical.nii'\n",
    "\n",
    "seeds = [L_amyg, R_amyg]\n",
    "\n",
    "TR = 1.5\n",
    "\n",
    "conditions = ['punish','reward','neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import abspath\n",
    "from pandas import DataFrame,Series,read_table,concat\n",
    "from math import isnan\n",
    "\n",
    "run_timing_list = glob(\"/Users/catcamacho/Box/LNCD_rewards_connectivity/subjs/10766/3_20130130/timing/*score_timing.txt\")\n",
    "run_timing_list = sorted(run_timing_list)\n",
    "\n",
    "dfs = [ read_table(i,sep=' ') for i in run_timing_list ]\n",
    "k=1\n",
    "for df in dfs:\n",
    "    df.loc[:,'runNum'] = Series(k, index = df.index)\n",
    "    df.loc[:,'time_hyp'] = (k-1)*453 + df.loc[:,'time_hyp']\n",
    "    k = k+1\n",
    "df_full = concat(dfs)\n",
    "df_full = df_full.sort(['runNum','time_hyp'], ascending=[1,1])\n",
    "df_responded = df_full[df_full.loc[:,'Count'] == 1]\n",
    "df_responded = df_responded[df_responded.loc[:,'catch']==0]\n",
    "\n",
    "df_punish = df_responded[df_responded.loc[:,'cond']=='punish']\n",
    "df_reward = df_responded[df_responded.loc[:,'cond']=='reward']\n",
    "df_neutral = df_responded[df_responded.loc[:,'cond']=='neutral']\n",
    "#print(df_reward)\n",
    "print(df_punish)\n",
    "#print(df_neutral)\n",
    "#print(df_punish['time_hyp'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid','timepoint']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list),('timepoint', timepoints)]\n",
    "infosource.synchronize = True\n",
    "\n",
    "#grab timing files\n",
    "time_template = {'timing':raw_dir + '/%s/%d_*/timing/*score_timing.txt'}\n",
    "timegrabber = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = raw_dir + '/%s/%d_*/timing/*score_timing.txt',\n",
    "                               field_template = time_template,\n",
    "                               base_directory=raw_dir,\n",
    "                               infields=['subjid','timepoint'], \n",
    "                               template_args={'timing':[['subjid','timepoint']]}), \n",
    "                   name='timegrabber')\n",
    "\n",
    "# Grab niftis\n",
    "template = {'struct':preproc_dir + '/preproc_anat/{subjid}_t{timepoint}/reoriented_anat.nii',\n",
    "            'func': preproc_dir + '/preproc_func/{subjid}_t{timepoint}/func_filtered.nii'}\n",
    "datasource = Node(SelectFiles(template), \n",
    "                  name = 'datasource')\n",
    "\n",
    "#sink important data\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_timepoint_','_t')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=firstlevel_dir,\n",
    "                         container=firstlevel_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract timing for Beta Series Method \n",
    "def timing_bars(run_timing_list, condition):\n",
    "    from os.path import abspath\n",
    "    from pandas import DataFrame,Series,read_table,concat\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    run_length = 453\n",
    "    run_timing_list = sorted(run_timing_list)\n",
    "\n",
    "    dfs = [ read_table(i,sep=' ') for i in run_timing_list ]\n",
    "    k=1\n",
    "    for df in dfs:\n",
    "        df.loc[:,'runNum'] = Series(k, index = df.index)\n",
    "        df.loc[:,'time_hyp'] = (k-1)*run_length + df.loc[:,'time_hyp']\n",
    "        k = k+1\n",
    "    df_full = concat(dfs)\n",
    "    df_full = df_full.sort(['runNum','time_hyp'], ascending=[1,1])\n",
    "    df_responded = df_full[df_full.loc[:,'Count'] == 1]\n",
    "    df_responded = df_responded[df_responded.loc[:,'catch']==0]\n",
    "\n",
    "    df_condition = df_responded[df_responded.loc[:,'cond']==condition]\n",
    "    \n",
    "    # create run number list\n",
    "    \n",
    "    \n",
    "    # create onset list\n",
    "    all_onsets = df_condition['time_hyp'].to_list()\n",
    "    \n",
    "    # create condition names\n",
    "    \n",
    "    \n",
    "    #make bunch file\n",
    "    timing = []\n",
    "    timing.insert(0,Bunch(conditions=trialNames,\n",
    "                          onsets=onsets,\n",
    "                          durations=[[1.5] for s in trialNames],\n",
    "                          amplitudes=None,\n",
    "                          tmod=None,\n",
    "                          pmod=None,\n",
    "                          regressor_names=None,\n",
    "                          regressors=None))\n",
    "    return(timing)\n",
    "\n",
    "\n",
    "# Brightness threshold should be 0.75 * the contrast between the median brain intensity and the background\n",
    "def calc_brightness_threshold(func_vol):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    brightness_threshold = 0.75 * median_thresh\n",
    "    return(brightness_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract timing\n",
    "pull_timing = Node(Function(input_names=['run_timing_list','condition'],\n",
    "                            output_names=['timing'],\n",
    "                            function=timing_bars), name='pull_timing')\n",
    "\n",
    "# Specify FSL model - input bunch file called subject_info\n",
    "modelspec = Node(SpecifyModel(time_repetition=TR, \n",
    "                              input_units='secs'),\n",
    "                 name='modelspec')\n",
    "\n",
    "# Generate a level 1 design\n",
    "level1design = Node(Level1Design(bases={'dgamma':{'derivs': False}},\n",
    "                                 interscan_interval=TR, # the TR\n",
    "                                 model_serial_correlations=True,\n",
    "                                 contrasts=contrasts_list), \n",
    "                    name='level1design')\n",
    "\n",
    "# Estimate Level 1\n",
    "generateModel = Node(FEATModel(), \n",
    "                     name='generateModel')\n",
    "\n",
    "# Run GLM\n",
    "extract_beta_series = Node(GLM(out_file='betas.nii'), \n",
    "                           name='extract_beta_series')\n",
    "\n",
    "# Calculate brightness threshold\n",
    "calc_bright_thresh = Node(Function(input_names=['func_vol'],\n",
    "                                   output_names=['brightness_threshold'],\n",
    "                                   function=calc_brightness_threshold), \n",
    "                          name='calc_bright_thresh')\n",
    "\n",
    "# Smooth parameter estimates- input brightness_threshold and in_file; output smoothed_file\n",
    "smooth = Node(SUSAN(fwhm=smoothing_kernel), \n",
    "              name='smooth')\n",
    "\n",
    "# Merge PEs to 1 4D volume per condition\n",
    "merge_series = Node(Merge(dimension='t'), \n",
    "                    name='merge_series')\n",
    "\n",
    "# Register to MNI space\n",
    "reg_anat2mni = Node(FLIRT(out_matrix_file='transform.mat',\n",
    "                          reference=MNI_template),\n",
    "                    name='reg_anat2mni')\n",
    "\n",
    "reg_betas2mni = Node(FLIRT(apply_xfm=True,\n",
    "                           reference=MNI_template), \n",
    "                     name='reg_betas2mni')\n",
    "\n",
    "# Extract ROI beta series: input mask and in_file, output out_file\n",
    "extract_ROI_betas = Node(ImageMeants(), name='extract_ROI_betas')\n",
    "\n",
    "# Extract beta connectivity\n",
    "beta_series_conn = Node(GLM(out_file='betas.nii',\n",
    "                            out_cope='cope.nii'), \n",
    "                        name='beta_series_conn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect the workflow\n",
    "level1workflow = Workflow(name='level1workflow')\n",
    "level1workflow.connect([(infosource, datasource,[('subjid','subjid')]),\n",
    "                        (infosource, datasource,[('timepoint','timepoint')]),\n",
    "                        (datasource, merge, [('func','in_files')]),\n",
    "                        \n",
    "                        (merge,datasink,[('merged_file','merged_runs')])\n",
    "                       ])\n",
    "level1workflow.base_dir = join(workflow_dir)\n",
    "level1workflow.write_graph(graph2use='flat')\n",
    "level1workflow.run('MultiProc', plugin_args={'n_procs': 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
