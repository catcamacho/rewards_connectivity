{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from os.path import join\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl.utils import Merge, ImageMeants, Split\n",
    "from nipype.interfaces.fsl.model import Randomise, Cluster\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from nipype.interfaces.fsl.maths import ApplyMask, Threshold\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# Set study variables\n",
    "analysis_home = '/Users/catcamacho/Box/LNCD_rewards_connectivity'\n",
    "#analysis_home = '/Volumes/Zeus/Cat'\n",
    "firstlevel_dir = analysis_home + '/proc/firstlevel'\n",
    "secondlevel_dir = analysis_home + '/proc/secondlevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "template_dir = analysis_home + '/templates'\n",
    "MNI_template = template_dir + '/MNI152_T1_1mm_brain.nii'\n",
    "MNI_mask = template_dir + '/MNI152_T1_3mm_mask.nii'\n",
    "\n",
    "#pull subject info \n",
    "subject_info = analysis_home + '/misc/subjs.csv'\n",
    "\n",
    "conditions = ['punish','neutral']\n",
    "seed_names = ['L_amyg','R_amyg']\n",
    "\n",
    "# Group analysis models (predicting FC)\n",
    "models = ['brain ~ ageMC + sex + ageMC*sex', \n",
    "          'brain ~ invAgeMC + sex + invAgeMC*sex']\n",
    "\n",
    "model_names = ['linearAge', 'inverseAge']\n",
    "\n",
    "terms = ['age', 'sex', 'ageSexInteract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LMEM for MRI data (3D nifti data)\n",
    "def mri_lmem(model, mask, subject_dataframe, subject_files, grouping_variable):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "\n",
    "    from os import getcwd\n",
    "    from os.path import abspath\n",
    "    import statsmodels.formula.api as smf\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import array, empty_like, stack, nditer, zeros_like, zeros\n",
    "    from pandas import DataFrame, read_csv, Series, concat\n",
    "    from warnings import filterwarnings\n",
    "    filterwarnings(\"ignore\")\n",
    "\n",
    "    working_dir = getcwd() + '/'\n",
    "    subj_data = read_csv(subject_dataframe, header=0, index_col=0)\n",
    "\n",
    "    # Load the brain data\n",
    "    brain_niftis = load(subject_files)\n",
    "    brain_data_4D = brain_niftis.get_data()\n",
    "\n",
    "    # Load the mask\n",
    "    mask_nifti = load(mask)\n",
    "    mask = mask_nifti.get_data()\n",
    "\n",
    "    ## Preallocate the output arrays\n",
    "    # for the model\n",
    "    BIC_data = zeros_like(mask).astype(float)\n",
    "    AIC_data = zeros_like(mask).astype(float)\n",
    "    pval_intercept_data = zeros_like(mask).astype(float)\n",
    "    pval_age_data = zeros_like(mask).astype(float)\n",
    "    pval_sex_data = zeros_like(mask).astype(float)\n",
    "    pval_ageSexInteract_data = zeros_like(mask).astype(float)\n",
    "    # per subject\n",
    "    residuals_data = zeros_like(brain_data_4D).astype(float)\n",
    "    pred_values_data = zeros_like(brain_data_4D).astype(float)\n",
    "\n",
    "    # Set up the actual loops to pull in subject data and do the modeling\n",
    "    for x in range(0,mask.shape[0]):\n",
    "        for y in range(0,mask.shape[1]):\n",
    "            for z in range(0,mask.shape[2]):\n",
    "                if mask[x][y][z] == 1:\n",
    "                    voxel = zeros(brain_data_4D.shape[3])\n",
    "                    for a in range(0,brain_data_4D.shape[3]):\n",
    "                        voxel[a] = brain_data_4D[x][y][z][a]\n",
    "                    voxel = Series(voxel, index=subj_data.index, name='brain')\n",
    "                    data = concat([voxel, subj_data],axis=1)\n",
    "                    mlm = smf.mixedlm(model, data, groups=data[grouping_variable])\n",
    "                    mod = mlm.fit()\n",
    "                    pval_intercept_data[x][y][z] = 1 - mod.pvalues[0]\n",
    "                    pval_age_data[x][y][z] = 1 - mod.pvalues[1]\n",
    "                    pval_sex_data[x][y][z] = 1 - mod.pvalues[2]\n",
    "                    pval_ageSexInteract_data[x][y][z] = 1 - mod.pvalues[3]\n",
    "                    BIC_data[x][y][z] = mod.bic\n",
    "                    AIC_data[x][y][z] = mod.aic\n",
    "                    residuals = mod.resid\n",
    "                    pred_values = Series(mod.predict(), index = subj_data.index)\n",
    "                    for d in range(0,brain_data_4D.shape[3]):\n",
    "                        residuals_data[x][y][z][d] = residuals.tolist()[d]\n",
    "                        pred_values_data[x][y][z][d] = pred_values.tolist()[d]\n",
    "\n",
    "                \n",
    "    # Save the ouputs as nifti files\n",
    "    output_data = [BIC_data, AIC_data, pval_intercept_data, pval_age_data,\n",
    "                    pval_sex_data, pval_ageSexInteract_data, residuals_data, \n",
    "                    pred_values_data]\n",
    "    output_niftis = [Nifti1Image(result, mask_nifti.affine) for result in output_data]\n",
    "    \n",
    "    output_filenames = ['BICs.nii','AICs.nii','pval_intercept_data.nii',\n",
    "                        'pval_age_data.nii','pval_sex_data.nii',\n",
    "                        'pval_ageSexInteract_data.nii','residuals_data.nii',\n",
    "                        'pred_values_data.nii']\n",
    "    for e in range(0,len(output_niftis)):\n",
    "        save(output_niftis[e], working_dir + output_filenames[e])\n",
    "    \n",
    "    output_volumes = [abspath(output_filenames[0]),\n",
    "                      abspath(output_filenames[1]),\n",
    "                      abspath(output_filenames[2]), \n",
    "                      abspath(output_filenames[3]), \n",
    "                      abspath(output_filenames[4]), \n",
    "                      abspath(output_filenames[5]), \n",
    "                      abspath(output_filenames[6]), \n",
    "                      abspath(output_filenames[7])]\n",
    "    \n",
    "    return(output_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data handling nodes\n",
    "\n",
    "conditionsource = Node(IdentityInterface(fields=['condition','seed']),\n",
    "                       name='conditionsource')\n",
    "conditionsource.iterables = [('condition',conditions),('seed', seed_names)]\n",
    "\n",
    "# Grab the subject beta maps \n",
    "time_template = {'beta_maps':firstlevel_dir + '/smoothedMNI_conn_beta/*/%s/%s/betas_flirt_smooth_masked.nii'}\n",
    "betamap_grabber = Node(DataGrabber(sort_filelist=True,\n",
    "                                   field_template = time_template,\n",
    "                                   base_directory=firstlevel_dir,\n",
    "                                   template=firstlevel_dir + '/smoothedMNI_conn_beta/*/%s/%s/betas_flirt_smooth_masked.nii',\n",
    "                                   infields=['condition','seed'],\n",
    "                                   template_args={'beta_maps':[['condition','seed']]}), \n",
    "                       name='betamap_grabber')\n",
    "\n",
    "# Sink relavent data\n",
    "substitutions = [('_condition_',''),\n",
    "                 ('_seed_',''), \n",
    "                 ('brain~ageMC+sex+ageMC*sex','linearAge'),\n",
    "                 ('brain~invAgeMC+sex+invAgeMC*sex','inverseAge')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=secondlevel_dir,\n",
    "                         container=secondlevel_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Analysis nodes\n",
    "\n",
    "#Merge subject files together\n",
    "merge = Node(Merge(dimension='t'), name='merge')\n",
    "\n",
    "# Linear mixed effects modeling\n",
    "lmemodel = Node(Function(input_names = ['model', 'mask', 'subject_dataframe', \n",
    "                                        'subject_files', 'grouping_variable'], \n",
    "                         output_names = ['output_volumes'], \n",
    "                         function=mri_lmem), \n",
    "                name='lmemodel')\n",
    "lmemodel.iterables = [('model', models)]\n",
    "lmemodel.inputs.mask = MNI_mask\n",
    "lmemodel.inputs.subject_dataframe = subject_info\n",
    "lmemodel.inputs.grouping_variable = 'Timepoint'\n",
    "\n",
    "# Mask the file to only significant voxels for clustering\n",
    "mask_stat = Node(Binarize(), name = 'mask_stat')\n",
    "\n",
    "# Cluster the results\n",
    "cluster_results = MapNode(Cluster(threshold=0.95,\n",
    "                                  out_index_file=True,\n",
    "                                  out_localmax_txt_file=True),\n",
    "                          name='cluster_results', \n",
    "                          iterfield = ['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LMEManalysisflow = Workflow(name='LMEManalysisflow')\n",
    "LMEManalysisflow.connect([(conditionsource, betamap_grabber, [('condition','condition'),\n",
    "                                                              ('seed','seed')]),\n",
    "                          (betamap_grabber, merge, [('beta_maps','in_files')]),\n",
    "                          (merge, lmemodel, [('merged_file','subject_files')]),\n",
    "                          (merge, datasink, [('merged_file','merged_subj_betas')]),\n",
    "                          (lmemodel, datasink, [('output_volumes','output_volumes')])\n",
    "                         ])\n",
    "#LMEManalysisflow.base_dir = workflow_dir\n",
    "#LMEManalysisflow.write_graph(graph2use='flat')\n",
    "#LMEManalysisflow.run('MultiProc', plugin_args={'n_procs':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_clusters(cluster_index):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "\n",
    "    from os import getcwd\n",
    "    from os.path import abspath\n",
    "    from nibabel import load, save, Nifti1Image\n",
    "    from numpy import unique, amax, stack, zeros_like\n",
    "\n",
    "    cluster_min = 20\n",
    "    nifti = load(cluster_index)\n",
    "    data = nifti.get_data()\n",
    "    clust_labels, vox_count = unique(data, return_counts=True)\n",
    "    clust_labels = clust_labels.tolist()\n",
    "    vox_count = vox_count.tolist()\n",
    "\n",
    "    iter = 0\n",
    "    for i in range(0, len(clust_labels)):\n",
    "        if vox_count[i] < cluster_min:\n",
    "            del(clust_labels[i-iter])\n",
    "            iter = iter +1\n",
    "\n",
    "    clust_labels = clust_labels[1:]\n",
    "    num_clusters = len(clust_labels)\n",
    "\n",
    "    cluster_masks = []\n",
    "    for a in range(0,num_clusters):\n",
    "        temp = zeros_like(data)\n",
    "        temp[data==clust_labels[a]] = 1\n",
    "        cluster_masks.append(temp)\n",
    "\n",
    "    cluster_masks_4D = stack(cluster_masks,axis=3)\n",
    "    cluster_masks_nifti = Nifti1Image(cluster_masks_4D, nifti.affine)\n",
    "    save(cluster_masks_nifti, 'new_clust_index.nii')\n",
    "    newcluster_index = abspath('new_clust_index.nii')\n",
    "    return(newcluster_index)\n",
    "\n",
    "\n",
    "def finalize_models(cluster, template, betas_text_file, subj_data, model_name):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "    import statsmodels.formula.api as smf\n",
    "    from pandas import DataFrame, Series, concat, read_table, read_csv\n",
    "    from ggplot import *\n",
    "    from warnings import filterwarnings\n",
    "    filterwarnings(\"ignore\")\n",
    "    import sys\n",
    "    from nilearn import plotting\n",
    "    \n",
    "    #determine which model to use\n",
    "    if model_name=='linearAge':\n",
    "        model = 'brain ~ ageMC + sex + ageMC*sex'\n",
    "    elif model_name=='inverseAge':\n",
    "        model = 'brain ~ invAgeMC + sex + invAgeMC*sex'\n",
    "        \n",
    "    origstdout = sys.stdout\n",
    "    sys.stdout = open('modelsummary.txt', 'w')\n",
    "\n",
    "    #organize data into dataframe for modeling\n",
    "    subj_data = read_csv(subj_data, header=0, index_col=0)\n",
    "    brain_data = read_table(betas_text_file, header=None, names='brain', index_col=None)\n",
    "    data = concat([brain_data, subj_data],axis=1)\n",
    "    # do the modeling\n",
    "    mlm = smf.mixedlm(model, data, groups=data[grouping_variable])\n",
    "    mod = mlm.fit()\n",
    "    print(mod.summary())\n",
    "    sys.stdout = origstdout\n",
    "    close('modelsummary.txt')\n",
    "    summary_file = abspath('modelsummary.txt')\n",
    "    \n",
    "    # plot the model results\n",
    "    figure = ggplot(data, aes(x='age',y='brain') + theme_classic() + \n",
    "                    geom_point() + geom_smooth(method=lm,se=True, size=2))\n",
    "    figure.save('plot.svg')\n",
    "    figure_file = abspath('plot.svg')\n",
    "    \n",
    "    # make a picture of the brain cluster\n",
    "    display = plotting.plot_anat(anat_img = template, display_mode='x')\n",
    "    display.add_overlay(cluster, plotting.cm.purple_green, threshold=1)\n",
    "    display.savefig('clusterpic.png')\n",
    "    display.close()\n",
    "    clusterpic_file = abspath('clusterpic.png')\n",
    "    \n",
    "    outputs = [summary_file, figure_file, clusterpic_file]\n",
    "    \n",
    "    return(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab data outputs from the LMEMs\n",
    "infosource = Node(IdentityInterface(fields=['condition','seed','term','model']),\n",
    "                  name='conditionsource')\n",
    "infosource.iterables = [('condition', conditions), \n",
    "                        ('seed', seed_names), \n",
    "                        ('term', terms), \n",
    "                        ('model', model_names)]\n",
    "\n",
    "lme_template = {'pval_vol': secondlevel_dir + '/output_volumes/{condition}{seed}/_model_{model}/pval_{term}_data.nii', \n",
    "                'subj_beta_data': secondlevel_dir + '/merged_betas/betas_merged.nii'}            \n",
    "lme_datagrabber = Node(SelectFiles(lme_template), name='lme_datagrabber') \n",
    "\n",
    "# Threshold out nonsignificant voxels\n",
    "threshold = Node(Threshold(thresh=0.95), name='threshold')\n",
    "\n",
    "# Cluster the remaining volumes\n",
    "cluster = Node(Cluster(threshold=0.95, \n",
    "                       out_index_file=True, \n",
    "                       use_mm=True,\n",
    "                       minclustersize=True,\n",
    "                       peak_distance=6), \n",
    "               name='cluster')\n",
    "\n",
    "# remove small clusters\n",
    "cluster_min = Node(Function(input_names=['cluster_index'], \n",
    "                            output_names=['newcluster_index'], \n",
    "                            function=threshold_clusters), \n",
    "                   name='cluster_min')\n",
    "\n",
    "# Split the clusters\n",
    "split = Node(Split(dimension='t'),\n",
    "             name='split')\n",
    "\n",
    "# Extract mean connectivity per cluster\n",
    "pull_mean_betas = MapNode(ImageMeants(out_file='mean_connectivity.txt'), \n",
    "                          name= 'pull_mean_betas', \n",
    "                          iterfield=['mask'])\n",
    "                         \n",
    "\n",
    "# graph the connectivity against age and re-do the linear models\n",
    "finalize_models = MapNode(Function(input_names=['cluster','template','betas_text_file','subj_data', 'model_name'], \n",
    "                                   output_names=['outputs'], \n",
    "                                   function=finalize_models),\n",
    "                          name='finalize_models', \n",
    "                          iterfield=['betas_text_file'])\n",
    "finalize_models.inputs.subj_data=subject_info\n",
    "finalize_models.inputs.template=MNI_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusterflow = Workflow(name='clusterflow')\n",
    "clusterflow.connect([(infosource, lme_datagrabber, [('condition','condition'),\n",
    "                                                    ('seed','seed'),\n",
    "                                                    ('term','term'),\n",
    "                                                    ('model','model')]),\n",
    "                     (lme_datagrabber,threshold, [('pval_vol','in_file')]),\n",
    "                     (threshold, cluster, [('out_file','in_file')]),\n",
    "                     (cluster, cluster_min, [('index_file','cluster_index')]),\n",
    "                     (cluster_min, split, [('newcluster_index','in_file')]),\n",
    "                     (split, pull_mean_betas, [('out_files','mask')]),\n",
    "                     (lme_datagrabber, pull_mean_betas, [('subj_beta_data','in_file')]),\n",
    "                     \n",
    "                     (pull_mean_betas, datasink, [('out_file','beta_values')]),\n",
    "                     (cluster, datasink, [('index_file','cluster_index_file'),\n",
    "                                          ('localmax_txt_file','cluster_localmax_txt_file')]),\n",
    "                     (split,datasink,[('out_files','final_clusters')])\n",
    "                    ])\n",
    "clusterflow.base_dir = workflow_dir\n",
    "clusterflow.write_graph(graph2use='flat')\n",
    "clusterflow.run('MultiProc', plugin_args={'n_procs':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
