{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from os.path import join\n",
    "from pandas import DataFrame\n",
    "\n",
    "from nipype.pipeline.engine import Workflow, Node, MapNode\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import DataSink, DataGrabber, FreeSurferSource\n",
    "from nipype.algorithms.misc import Gunzip\n",
    "\n",
    "from nipype.interfaces.freesurfer.preprocess import ReconAll, MRIConvert\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from nipype.interfaces.freesurfer import FSCommand\n",
    "from nipype.interfaces.fsl.utils import Reorient2Std, Merge\n",
    "from nipype.interfaces.fsl.preprocess import MCFLIRT, SliceTimer, FLIRT, FAST\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype.interfaces.fsl.model import GLM\n",
    "from nipype.algorithms.confounds import CompCor\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# Set study variables\n",
    "#analysis_home = '/Users/catcamacho/Box/LNCD_rewards_connectivity'\n",
    "analysis_home = '/Volumes/Zeus/Cat'\n",
    "#raw_dir = analysis_home + '/subjs'\n",
    "raw_dir = '/Volumes/Phillips/bars/APWF_bars/subjs'\n",
    "preproc_dir = analysis_home + '/proc/preprocessing'\n",
    "firstlevel_dir = analysis_home + '/proc/firstlevel'\n",
    "secondlevel_dir = analysis_home + '/proc/secondlevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "\n",
    "subject_info = DataFrame.from_csv(analysis_home + '/misc/subjs.csv')\n",
    "subjects_list = subject_info['SubjID'].tolist()\n",
    "timepoints = subject_info['Timepoint'].tolist()\n",
    "\n",
    "# FreeSurfer set up - change SUBJECTS_DIR \n",
    "fs_dir = analysis_home + '/proc/freesurfer'\n",
    "FSCommand.set_default_subjects_dir(fs_dir)\n",
    "\n",
    "# data collection specs\n",
    "TR = 1.5 #in seconds\n",
    "num_slices = 29\n",
    "slice_direction = 3 #3 = z direction\n",
    "interleaved = False\n",
    "#all rates are in Hz (1/TR or samples/second)\n",
    "highpass_freq = 0.01 #in Hz\n",
    "lowpass_freq = 1 #in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid','timepoint']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list),('timepoint', timepoints)]\n",
    "infosource.synchronize = True\n",
    "\n",
    "#grab niftis\n",
    "func_template = {'func':raw_dir + '/%s/%d_*/*/functional/functional.nii.gz'}\n",
    "funcgrabber = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = raw_dir + '/%s/%d_*/*/functional/functional.nii.gz',\n",
    "                               field_template = func_template,\n",
    "                               base_directory=raw_dir,\n",
    "                               infields=['subjid','timepoint'], \n",
    "                               template_args={'func':[['subjid','timepoint']]}), \n",
    "                   name='funcgrabber')\n",
    "\n",
    "struct_template = {'struct':raw_dir + '/%s/%d_*/mprage/mprage.nii.gz'}\n",
    "structgrabber = Node(DataGrabber(sort_filelist=True,\n",
    "                                 template = raw_dir + '/%s/%d_*/mprage/mprage.nii.gz',\n",
    "                                 field_template = struct_template,\n",
    "                                 base_directory=raw_dir,\n",
    "                                 infields=['subjid','timepoint'], \n",
    "                                 template_args={'struct':[['subjid','timepoint']]}), \n",
    "                     name='structgrabber')\n",
    "\n",
    "fssource = Node(FreeSurferSource(subjects_dir=fs_dir), \n",
    "                name = 'fssource')\n",
    "\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_timepoint_','_t')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=preproc_dir,\n",
    "                         container=preproc_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom functions for anatomical processing\n",
    "def numberedsub_convert(subjid,timepoint):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    fs_subjid = 's' + str(subjid) + '_' + str(timepoint)\n",
    "    return(fs_subjid)\n",
    "\n",
    "# Process subjects through recon-all and deposit in subjects_dir\n",
    "def proc_fs(anat,fs_subjid,subjects_dir):\n",
    "    from os.path import abspath\n",
    "    from os import getcwd\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from glob import glob\n",
    "    from subprocess import call\n",
    "    \n",
    "    call(['recon-all','-s',fs_subjid,'-sd',subjects_dir,'-i',anat,'-autorecon1','-autorecon2'])\n",
    "    script_path = subjects_dir + '/' + fs_subjid + '/scripts/recon-all.done'\n",
    "    \n",
    "    return(script_path)\n",
    "\n",
    "# Structural processing\n",
    "get_fsID = Node(Function(input_names=['subjid','timepoint'],\n",
    "                         output_names=['fs_subjid'],\n",
    "                         function=numberedsub_convert),\n",
    "                name='get_fsID')\n",
    "\n",
    "# Use autorecon1 to skullstrip inputs: T1_files and subject_id; output: brainmask, aseg\n",
    "fs_preproc = Node(Function(input_names=['anat','fs_subjid','subjects_dir'],\n",
    "                           output_names=['script_path'],\n",
    "                           function=proc_fs), \n",
    "                  name='fs_preproc')\n",
    "fs_preproc.inputs.subjects_dir=fs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsprocflow = Workflow(name='fsprocflow')\n",
    "fsprocflow.connect([(infosource,structgrabber,[('subjid','subjid')]),\n",
    "                    (infosource,structgrabber,[('timepoint','timepoint')]),\n",
    "                    (structgrabber,fs_preproc,[('struct','anat')]),\n",
    "                    (infosource,get_fsID,[('subjid','subjid')]),\n",
    "                    (infosource,get_fsID,[('timepoint','timepoint')]),\n",
    "                    (get_fsID,fs_preproc,[('fs_subjid','fs_subjid')]),\n",
    "                    (fs_preproc,datasink,[('script_path','script_path')])\n",
    "                   ])\n",
    "fsprocflow.base_dir = workflow_dir\n",
    "fsprocflow.write_graph(graph2use='flat')\n",
    "fsprocflow.run('MultiProc', plugin_args={'n_procs': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simultaneously convert to nifti and reslice inputs: in_file outputs: out_file\n",
    "convert_anat = Node(MRIConvert(vox_size=(3,3,3), \n",
    "                               in_type='mgz',\n",
    "                               out_file='anat.nii',\n",
    "                               out_type='nii'), \n",
    "                    name='convert_anat')\n",
    "\n",
    "# simultaneously convert to nifti and reslice inputs: in_file outputs: out_file\n",
    "convert_aseg = Node(MRIConvert(vox_size=(3,3,3), \n",
    "                               in_type='mgz',\n",
    "                               out_file='aseg.nii',\n",
    "                               out_type='nii'), \n",
    "                    name='convert_aseg')\n",
    "\n",
    "# reorient to standard space inputs: in_file, outputs: out_file\n",
    "reorient_anat = Node(Reorient2Std(out_file='reoriented_anat.nii',\n",
    "                                  output_type='NIFTI'), \n",
    "                     name='reorient_anat')\n",
    "\n",
    "# reorient to standard space inputs: in_file, outputs: out_file\n",
    "reorient_aseg = Node(Reorient2Std(out_file='reoriented_aseg.nii',\n",
    "                                  output_type='NIFTI'), \n",
    "                     name='reorient_aseg')\n",
    "\n",
    "# binarize anat, dilate 2 and erode 1 to fill gaps. Inputs: in_file; outputs: binary_file\n",
    "binarize_anat = Node(Binarize(dilate=2,\n",
    "                              erode=1, \n",
    "                              min=1,\n",
    "                              max=300), \n",
    "                     name='binarize_anat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom functions referenced in the pipeline\n",
    "\n",
    "# this function demeans each run and sorts the file list\n",
    "def intensitycorrect(func_files):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from nipype.interfaces.fsl.utils import ImageMaths\n",
    "    \n",
    "    new_files = []\n",
    "    n = 1\n",
    "    for func in func_files:\n",
    "        out_file = 'demeaned_func' + str(n)+ '.nii'\n",
    "        math=ImageMaths()\n",
    "        math.inputs.in_file = func\n",
    "        math.inputs.out_file = out_file\n",
    "        math.inputs.op_string = '-Tmean -mul -1 -add %s' % func\n",
    "        math.run()\n",
    "        demeaned_vol = abspath(out_file)\n",
    "        new_files.append(demeaned_vol)\n",
    "    \n",
    "    new_func_list = sorted(new_files)\n",
    "    return(new_func_list)\n",
    "\n",
    "def concatenatemotion(motion_files,merged_func):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from numpy import genfromtxt, vstack, savetxt\n",
    "    from nibabel import load\n",
    "    from warnings import warn\n",
    "    \n",
    "    func = load(merged_func)\n",
    "    func_length = func.shape[3]\n",
    "    \n",
    "    n = 1\n",
    "    for file in motion_files:\n",
    "        temp = genfromtxt(file)\n",
    "        if n == 1:\n",
    "            all_motion=temp\n",
    "        else:\n",
    "            all_motion=vstack((all_motion,temp))\n",
    "        n=n+1\n",
    "    \n",
    "    if func_length == all_motion.shape[0]:\n",
    "        newmotion_file = 'allmotion.txt'\n",
    "        savetxt(newmotion_file,all_motion)\n",
    "        newmotion_params = abspath(newmotion_file)\n",
    "    else:\n",
    "        warn('The dimensions from your motion outputs do not match your functional data!')\n",
    "        newmotion_file = 'allmotion.txt'\n",
    "        savetxt(newmotion_file,all_motion)\n",
    "        newmotion_params = abspath(newmotion_file)\n",
    "\n",
    "    return(newmotion_params)\n",
    "\n",
    "def bandpass_filter(in_file, lowpass, highpass, TR):\n",
    "    import numpy as np\n",
    "    import nibabel as nb\n",
    "    from os.path import abspath\n",
    "    from os import getcwd\n",
    "    from nipype.interfaces.afni.preprocess import Bandpass\n",
    "    from nipype.interfaces.afni.utils import AFNItoNIFTI\n",
    "    from nipype.algorithms.misc import Gunzip\n",
    "    from glob import glob\n",
    "    from subprocess import call\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    out_file = 'func_filtered'\n",
    "    call(['3dBandpass', '-prefix', out_file,'-dt', str(TR), str(highpass), str(lowpass), in_file])\n",
    "    filtered_file = glob(getcwd() + '/func_filtered*.BRIK*')\n",
    "    call([\"gunzip\", filtered_file[0]])\n",
    "    new_file = getcwd() +'/func_filtered+orig.BRIK'\n",
    "    call([\"3dAFNItoNIFTI\", new_file])\n",
    "    nii_file = glob(getcwd() + '/*.nii.gz')\n",
    "    call([\"gunzip\", nii_file[0]])\n",
    "    out_file = getcwd() + '/func_filtered.nii'\n",
    "    return(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functional processing\n",
    "\n",
    "unzip_func = MapNode(Gunzip(), \n",
    "                     name='unzip_func', \n",
    "                     iterfield=['in_file'])\n",
    "\n",
    "# Reorient each functional run in_file, out_file\n",
    "reorient_func = MapNode(Reorient2Std(out_file='reoriented_func.nii'),\n",
    "                        name='reorient_func', \n",
    "                        iterfield=['in_file'])\n",
    "\n",
    "# Realign each volume to first volume in each run: in_file; out_file, par_file\n",
    "realign_runs = MapNode(MCFLIRT(out_file='rfunc.nii',\n",
    "                               save_plots=True,\n",
    "                               save_rms=True), \n",
    "                       name='realign_runs',\n",
    "                       iterfield=['in_file'])\n",
    "\n",
    "# Slice time correction: in_file, slice_time_corrected_file\n",
    "slicetime = MapNode(SliceTimer(time_repetition=TR, \n",
    "                               interleaved=interleaved, \n",
    "                               slice_direction=slice_direction, \n",
    "                               out_file='stfunc.nii'), \n",
    "                    name='slicetime',\n",
    "                    iterfield=['in_file'])\n",
    "\n",
    "# register the functional volumes to the subject space anat\n",
    "# inputs: in_file, reference; out_file out_matrix_file\n",
    "reg_func_to_anat = MapNode(FLIRT(out_matrix_file='xform.mat'),\n",
    "                           name='reg_func_to_anat', \n",
    "                           iterfield=['in_file'])\n",
    "\n",
    "apply_reg_to_func = MapNode(FLIRT(apply_xfm=True, \n",
    "                               out_file='warped_func.nii'), \n",
    "                            name='apply_reg_to_func', \n",
    "                            iterfield=['in_file','in_matrix_file'])\n",
    "\n",
    "# Despiking and Intensity norm?\n",
    "norm_run_intensities = Node(Function(input_names=['func_files'], \n",
    "                                     output_names=['new_func_list'],\n",
    "                                     function=intensitycorrect),\n",
    "                            name='norm_run_intensities')\n",
    "\n",
    "# Merge the motion params into one long motion file: \n",
    "            # motion_files, merged_func; newmotion_params\n",
    "merge_motion = Node(Function(input_names=['motion_files','merged_func'], \n",
    "                             output_names=['newmotion_params'], \n",
    "                             function=concatenatemotion), \n",
    "                    name='merge_motion')\n",
    "\n",
    "# Merge all 4 runs: in_files, merged_file\n",
    "merge_func = Node(Merge(dimension='t',\n",
    "                        merged_file='merged_func.nii'),\n",
    "                  name='merge_func')\n",
    "\n",
    "# Realign each volume to first volume: in_file; out_file, par_file\n",
    "realign_merged = Node(MCFLIRT(out_file='rmerged.nii',\n",
    "                              ref_vol=0), \n",
    "                      name='realign_merged')\n",
    "\n",
    "# Apply binary mask to merged functional scan: in_file, mask_file; out_file\n",
    "mask_func = Node(ApplyMask(out_file='masked_func.nii'), \n",
    "                 name='mask_func')\n",
    "\n",
    "# Bandpass Filtering (0.01-0.1 per Rissman et al 2004) all rates are in Hz (1/TR or samples/second)\n",
    "bandpass = Node(name='bandpass', \n",
    "                interface=Function(input_names=['in_file','lowpass','highpass','TR'], \n",
    "                                   output_names=['out_file'],\n",
    "                                   function=bandpass_filter))\n",
    "bandpass.inputs.lowpass = lowpass_freq\n",
    "bandpass.inputs.highpass = highpass_freq\n",
    "bandpass.inputs.TR = TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Denoising\n",
    "def adjust_masks(masks):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.freesurfer.model import Binarize\n",
    "    #pve0 = csf, pve1 = gm, pve2 = wm\n",
    "    \n",
    "    origvols = sorted(masks)\n",
    "    csf = origvols[0]\n",
    "    wm = origvols[2]\n",
    "    vols = []\n",
    "    \n",
    "    binary = Binarize()\n",
    "    binary.inputs.in_file = wm\n",
    "    binary.inputs.min = 0.5\n",
    "    binary.inputs.max = 2\n",
    "    binary.inputs.binary_file = 'WM_seg.nii'\n",
    "    binary.run()\n",
    "    wm_new = abspath(binary.inputs.binary_file)\n",
    "    vols.append(wm_new)\n",
    "    \n",
    "    binary2 = Binarize()\n",
    "    binary2.inputs.in_file = csf\n",
    "    binary2.erode = 1\n",
    "    binary2.inputs.min = 0.5\n",
    "    binary2.inputs.max = 2\n",
    "    binary2.inputs.binary_file = 'CSF_seg.nii'\n",
    "    binary2.run()\n",
    "    csf_new = abspath(binary2.inputs.binary_file)\n",
    "    vols.append(csf_new)\n",
    "    \n",
    "    return(vols)\n",
    "    \n",
    "def create_noise_matrix(vols_to_censor,motion_params,comp_noise):\n",
    "    from numpy import genfromtxt, zeros, column_stack, savetxt\n",
    "    from os import path\n",
    "    \n",
    "    motion = genfromtxt(motion_params, delimiter=None, dtype=None, skip_header=0)\n",
    "    comp_noise = genfromtxt(comp_noise, delimiter=None, dtype=None, skip_header=1)\n",
    "    censor_vol_list = genfromtxt(vols_to_censor, delimiter=None, dtype=None, skip_header=0)\n",
    "    \n",
    "    try:\n",
    "        c = censor_vol_list.size\n",
    "    except:\n",
    "        c = 0\n",
    "    \n",
    "    d=len(comp_noise)\n",
    "\n",
    "    if c > 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        for t in range(c):\n",
    "            scrubbing[censor_vol_list[t],t] = 1\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    elif c == 1:\n",
    "        scrubbing = zeros((d,c),dtype=int)\n",
    "        scrubbing[censor_vol_list] = 1\n",
    "        noise_matrix = column_stack((motion,comp_noise,scrubbing))\n",
    "    else:\n",
    "        noise_matrix = column_stack((motion,comp_noise))\n",
    "    \n",
    "    noise_file = 'noise_matrix.txt'\n",
    "    savetxt(noise_file, noise_matrix)\n",
    "    noise_filepath = path.abspath(noise_file)\n",
    "    \n",
    "    return(noise_filepath)\n",
    "\n",
    "# Artifact detection for scrubbing/motion assessment\n",
    "art = Node(ArtifactDetect(mask_type='file',\n",
    "                          parameter_source='FSL',\n",
    "                          norm_threshold=0.9, #mutually exclusive with rotation and translation thresh\n",
    "                          zintensity_threshold=3,\n",
    "                          use_differences=[True, False]),\n",
    "           name='art')\n",
    "\n",
    "# Segment structural scan\n",
    "segment = Node(FAST(no_bias=True, \n",
    "                    segments=True, \n",
    "                    number_classes=3), \n",
    "               name='segment')\n",
    "\n",
    "# Fix the segmentations\n",
    "fix_confs = Node(name='fix_confs',\n",
    "                 interface=Function(input_names=['masks'], \n",
    "                                    output_names=['vols'],\n",
    "                                    function=adjust_masks))\n",
    "# actually run compcor\n",
    "compcor = Node(CompCor(merge_method='none'), \n",
    "               name='compcor')\n",
    "\n",
    "# Create a denoising mask with compcor + motion\n",
    "noise_mat = Node(name='noise_mat', interface=Function(input_names=['vols_to_censor','motion_params','comp_noise'],\n",
    "                                                      output_names=['noise_filepath'], \n",
    "                                                      function=create_noise_matrix))\n",
    "\n",
    "# Denoise the data\n",
    "denoise = Node(GLM(out_res_name='denoised_residuals.nii', \n",
    "                   out_data_name='denoised_func.nii'), \n",
    "               name='denoise')\n",
    "\n",
    "# Nuissance regression -ICA AROMA:  \n",
    "    # motion_parameters, in_file; aggr_denoised_file, nonaggr_denoised_file\n",
    "    # --> removed 9/27/17 because the included/required masks weren't in the correct space\n",
    "#ica_aroma = Node(ICA_AROMA(TR=TR,\n",
    "#                           denoise_type='both'), \n",
    "#                 name='ica_aroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QC nodes\n",
    "def create_coreg_plot(epi,anat):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    from nilearn import plotting\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    coreg_filename='coregistration.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'coregistration to anatomy')\n",
    "    display.add_edges(anat)\n",
    "    display.savefig(coreg_filename) \n",
    "    display.close()\n",
    "    coreg_file = abspath(coreg_filename)\n",
    "    \n",
    "    return(coreg_file)\n",
    "\n",
    "def check_mask_coverage(epi,brainmask):\n",
    "    from os.path import abspath\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    from nilearn import plotting\n",
    "    from numpy import sum, asarray, vstack\n",
    "    from nipype.interfaces.nipy.preprocess import Trim\n",
    "    \n",
    "    epiVol = 'firstVol.nii'\n",
    "    trim = Trim()\n",
    "    trim.inputs.in_file = epi\n",
    "    trim.inputs.out_file = epiVol\n",
    "    trim.inputs.end_index = 1\n",
    "    trim.inputs.begin_index = 0\n",
    "    trim.run()\n",
    "    \n",
    "    maskcheck_filename='maskcheck.png'\n",
    "    display = plotting.plot_anat(epiVol, display_mode='ortho',\n",
    "                                 draw_cross=False,\n",
    "                                 title = 'check brainmask coverage')\n",
    "    display.add_contours(brainmask,levels=[.5], colors='r')\n",
    "    display.savefig(maskcheck_filename) \n",
    "    display.close()\n",
    "    \n",
    "\n",
    "    maskcheck_file = abspath(maskcheck_filename)\n",
    "\n",
    "    return(maskcheck_file)\n",
    "\n",
    "make_coreg_img = Node(Function(input_names=['epi','anat'],\n",
    "                                         output_names=['coreg_file'],\n",
    "                                         function=create_coreg_plot),\n",
    "                      name='make_coreg_img')\n",
    "\n",
    "make_checkmask_img = Node(Function(input_names=['epi','brainmask'],\n",
    "                                         output_names=['maskcheck_file'],\n",
    "                                         function=check_mask_coverage),\n",
    "                          name='make_checkmask_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# workflow\n",
    "preprocflow = Workflow(name='preprocflow')\n",
    "preprocflow.connect([(infosource,get_fsID,[('subjid','subjid')]),\n",
    "                     (infosource,get_fsID,[('timepoint','timepoint')]),\n",
    "                     (get_fsID,fssource,[('fs_subjid','subject_id')]),\n",
    "                     (fssource, convert_anat,[('brainmask','in_file')]),\n",
    "                     (fssource, convert_aseg,[('aseg','in_file')]),\n",
    "                     (convert_anat,reorient_anat,[('out_file','in_file')]),\n",
    "                     (convert_aseg,reorient_aseg,[('out_file','in_file')]),\n",
    "                     (reorient_anat,segment,[('out_file','in_files')]),\n",
    "                     (segment,fix_confs,[('tissue_class_files','masks')]),\n",
    "                     (fix_confs,compcor,[('vols','mask_files')]),\n",
    "                     (reorient_anat, binarize_anat,[('out_file','in_file')]),\n",
    "                     (reorient_anat,reg_func_to_anat,[('out_file','reference')]),\n",
    "                     (reorient_anat,apply_reg_to_func,[('out_file','reference')]),\n",
    "                     (binarize_anat,mask_func,[('binary_file','mask_file')]),\n",
    "                     (binarize_anat,art,[('binary_file','mask_file')]),\n",
    "                     \n",
    "                     (infosource,funcgrabber,[('subjid','subjid')]),\n",
    "                     (infosource,funcgrabber,[('timepoint','timepoint')]),\n",
    "                     (funcgrabber,unzip_func,[('func','in_file')]),\n",
    "                     (unzip_func,reorient_func,[('out_file','in_file')]),\n",
    "                     (reorient_func,realign_runs,[('out_file','in_file')]),\n",
    "                     (realign_runs, slicetime,[('out_file','in_file')]),\n",
    "                     (slicetime,reg_func_to_anat,[('slice_time_corrected_file','in_file')]),\n",
    "                     (slicetime,apply_reg_to_func,[('slice_time_corrected_file','in_file')]),\n",
    "                     (reg_func_to_anat,apply_reg_to_func,[('out_matrix_file','in_matrix_file')]),\n",
    "                     (apply_reg_to_func,norm_run_intensities,[('out_file','func_files')]),\n",
    "                     (norm_run_intensities,merge_func,[('new_func_list','in_files')]),\n",
    "                     (merge_func,realign_merged,[('merged_file','in_file')]),\n",
    "                     (realign_merged,mask_func,[('out_file','in_file')]),\n",
    "                     \n",
    "                     (realign_runs,merge_motion,[('par_file','motion_files')]),\n",
    "                     (mask_func,merge_motion,[('out_file','merged_func')]),\n",
    "                     (mask_func,art,[('out_file','realigned_files')]),\n",
    "                     (merge_motion,art,[('newmotion_params','realignment_parameters')]),\n",
    "                     (mask_func,compcor,[('out_file','realigned_file')]),\n",
    "                     (compcor,noise_mat,[('components_file','comp_noise')]),\n",
    "                     (art,noise_mat,[('outlier_files','vols_to_censor')]),\n",
    "                     (merge_motion,noise_mat,[('newmotion_params','motion_params')]),\n",
    "                     (noise_mat,denoise,[('noise_filepath','design')]),\n",
    "                     (mask_func,denoise,[('out_file','in_file')]),\n",
    "                     (denoise,bandpass,[('out_data','in_file')]),\n",
    "                     \n",
    "                     (realign_merged,make_coreg_img,[('out_file','epi')]),\n",
    "                     (reorient_anat,make_coreg_img,[('out_file','anat')]),\n",
    "                     (realign_merged,make_checkmask_img,[('out_file','epi')]),\n",
    "                     (binarize_anat,make_checkmask_img,[('binary_file','brainmask')]),\n",
    "                     \n",
    "                     (merge_func,datasink,[('merged_file','merged_func')]),\n",
    "                     (make_coreg_img,datasink,[('coreg_file','coregcheck_image')]),\n",
    "                     (make_checkmask_img,datasink,[('maskcheck_file','maskcheck_image')]),\n",
    "                     (mask_func, datasink,[('out_file','orig_merged_func')]),\n",
    "                     (reorient_anat,datasink,[('out_file','preproc_anat')]),\n",
    "                     (reorient_aseg,datasink,[('out_file','aseg')]),\n",
    "                     (binarize_anat,datasink,[('binary_file','binarized_anat')]),\n",
    "                     (merge_motion, datasink,[('newmotion_params','motion_params')]),\n",
    "                     (noise_mat,datasink,[('noise_filepath','full_noise_mat')]),\n",
    "                     (art,datasink,[('plot_files','art_plot_files')]),\n",
    "                     (art,datasink,[('outlier_files','art_outlier_files')]),\n",
    "                     (bandpass,datasink,[('out_file','preproc_func')])        \n",
    "                    ])\n",
    "preprocflow.base_dir = workflow_dir\n",
    "preprocflow.write_graph(graph2use='flat')\n",
    "preprocflow.run('MultiProc', plugin_args={'n_procs': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
