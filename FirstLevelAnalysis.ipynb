{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from os.path import join\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl.preprocess import FLIRT, SUSAN\n",
    "from nipype.interfaces.fsl.utils import Merge, ImageMeants\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# Set study variables\n",
    "smoothing_kernel = 4\n",
    "\n",
    "analysis_home = '/Users/catcamacho/Box/LNCD_rewards_connectivity'\n",
    "#analysis_home = '/Volumes/Zeus/Cat'\n",
    "preproc_dir = analysis_home + '/subjs'\n",
    "raw_dir = analysis_home + '/subjs'\n",
    "#raw_dir = '/Volumes/Phillips/bars/APWF_bars/subjs'\n",
    "preproc_dir = analysis_home + '/proc/preprocessing'\n",
    "firstlevel_dir = analysis_home + '/proc/firstlevel'\n",
    "secondlevel_dir = analysis_home + '/proc/secondlevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "template_dir = analysis_home + '/templates'\n",
    "\n",
    "MNI_template = template_dir + '/MNI152_T1_2mm_brain.nii'\n",
    "#pull subject info to iter over\n",
    "#subject_info = DataFrame.from_csv(analysis_home + '/misc/subjs.csv')\n",
    "#subjects_list = subject_info['SubjID'].tolist()\n",
    "#timepoints = subject_info['Timepoint'].tolist()\n",
    "\n",
    "subjects_list = ['10766']\n",
    "timepoints = [1]\n",
    "\n",
    "# Seed locations and seed list\n",
    "seed_dir = analysis_home + '/seeds'\n",
    "L_amyg = seed_dir + '/L_amyg_anatomical.nii'\n",
    "R_amyg = seed_dir + '/R_amyg_anatomical.nii'\n",
    "\n",
    "seeds = [L_amyg, R_amyg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid','timepoint']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list),('timepoint', timepoints)]\n",
    "infosource.synchronize = True\n",
    "\n",
    "#grab timing files\n",
    "time_template = {'timing':raw_dir + '/%s/%d_*/timing/*score_timing.txt'}\n",
    "timegrabber = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = raw_dir + '/%s/%d_*/timing/*score_timing.txt',\n",
    "                               field_template = time_template,\n",
    "                               base_directory=raw_dir,\n",
    "                               infields=['subjid','timepoint'], \n",
    "                               template_args={'timing':[['subjid','timepoint']]}), \n",
    "                   name='timegrabber')\n",
    "\n",
    "# Grab niftis\n",
    "template = {'struct':preproc_dir + '/preproc_anat/{subjid}_t{timepoint}/reoriented_anat.nii',\n",
    "            'func': preproc_dir + '/preproc_func/{subjid}_t{timepoint}/func_filtered.nii'}\n",
    "datasource = Node(SelectFiles(template), \n",
    "                  name = 'datasource')\n",
    "\n",
    "#sink important data\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_timepoint_','_t')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=firstlevel_dir,\n",
    "                         container=firstlevel_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import abspath\n",
    "from pandas import DataFrame,Series,read_table,concat\n",
    "from math import isnan\n",
    "\n",
    "run_timing_list = glob(\"/Users/catcamacho/Box/LNCD_rewards_connectivity/subjs/10766/3_20130130/timing/*score_timing.txt\")\n",
    "run_timing_list = sorted(run_timing_list)\n",
    "\n",
    "dfs = [ read_table(i,sep=' ') for i in run_timing_list ]\n",
    "k=1\n",
    "for df in dfs:\n",
    "    df.loc[:,'runNum'] = Series(k, index = df.index)\n",
    "    df.loc[:,'time_hyp'] = (k-1)*453 + df.loc[:,'time_hyp']\n",
    "    k = k+1\n",
    "df_full = concat(dfs)\n",
    "df_full = df_full.sort(['runNum','time_hyp'], ascending=[1,1])\n",
    "df_responded = df_full[df_full.loc[:,'Count'] == 1]\n",
    "df_responded = df_responded[df_responded.loc[:,'catch']==0]\n",
    "\n",
    "df_punish = df_responded[df_responded.loc[:,'cond']=='punish']\n",
    "df_reward = df_responded[df_responded.loc[:,'cond']=='reward']\n",
    "df_neutral = df_responded[df_responded.loc[:,'cond']=='neutral']\n",
    "#print(df_reward)\n",
    "print(df_punish)\n",
    "print(df_neutral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract timing for Beta Series Method \n",
    "def timing_bars_punishment(run_timing_list):\n",
    "    from os.path import abspath\n",
    "    from pandas import DataFrame,Series,read_table,concat\n",
    "    run_length = 453\n",
    "    run_timing_list = sorted(run_timing_list)\n",
    "\n",
    "    dfs = [ read_table(i,sep=' ') for i in run_timing_list ]\n",
    "    k=1\n",
    "    for df in dfs:\n",
    "        df.loc[:,'runNum'] = Series(k, index = df.index)\n",
    "        df.loc[:,'time_hyp'] = (k-1)*run_length + df.loc[:,'time_hyp']\n",
    "        k = k+1\n",
    "    df_full = concat(dfs)\n",
    "    df_full = df_full.sort(['runNum','time_hyp'], ascending=[1,1])\n",
    "    df_responded = df_full[df_full.loc[:,'Count'] == 1]\n",
    "    df_responded = df_responded[df_responded.loc[:,'catch']==0]\n",
    "\n",
    "    df_punish = df_responded[df_responded.loc[:,'cond']=='punish']\n",
    "    df_reward = df_responded[df_responded.loc[:,'cond']=='reward']\n",
    "    df_neutral = df_responded[df_responded.loc[:,'cond']=='neutral']\n",
    "    return(timing_files_list)\n",
    "\n",
    "def create_design_mat(timing_files_list, motion):\n",
    "    return(design_mat)\n",
    "\n",
    "def calc_brightness_threshold(func_vol):\n",
    "    return(brightness_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up design matrix\n",
    "\n",
    "\n",
    "# Run GLM\n",
    "\n",
    "\n",
    "# Calculate brightness threshold\n",
    "calc_bright_thresh = Node(Function(input_names=['func_vol'],\n",
    "                                   output_names=['brightness_threshold'],\n",
    "                                   function=calc_brightness_threshold), \n",
    "                          name='calc_bright_thresh')\n",
    "\n",
    "# Smooth parameter estimates- input brightness_threshold and in_file; output smoothed_file\n",
    "smooth = Node(SUSAN(fwhm=smoothing_kernel), \n",
    "              name='smooth')\n",
    "\n",
    "# Merge PEs to 1 4D volume per condition\n",
    "merge_series = Node(Merge(dimension='t'), \n",
    "                    name='merge_series')\n",
    "\n",
    "# Register to MNI space\n",
    "reg_anat2mni = Node(FLIRT(out_matrix_file='transform.mat',\n",
    "                          reference=MNI_template),\n",
    "                    name='reg_anat2mni')\n",
    "\n",
    "reg_betas2mni = Node(FLIRT(apply_xfm=True,\n",
    "                           reference=MNI_template), \n",
    "                     name='reg_betas2mni')\n",
    "\n",
    "# Extract ROI beta series: input mask and in_file, output out_file\n",
    "extract_ROI_betas = Node(ImageMeants(), name='extract_ROI_betas')\n",
    "\n",
    "# Extract beta connectivity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect the workflow\n",
    "level1workflow = Workflow(name='level1workflow')\n",
    "level1workflow.connect([(infosource, datasource,[('subjid','subjid')]),\n",
    "                        (infosource, datasource,[('timepoint','timepoint')]),\n",
    "                        (datasource, merge, [('func','in_files')]),\n",
    "                        \n",
    "                        (merge,datasink,[('merged_file','merged_runs')])\n",
    "                       ])\n",
    "level1workflow.base_dir = join(workflow_dir)\n",
    "level1workflow.write_graph(graph2use='flat')\n",
    "level1workflow.run('MultiProc', plugin_args={'n_procs': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
