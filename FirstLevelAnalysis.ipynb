{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "from nipype.pipeline.engine import Workflow, Node\n",
    "from nipype.interfaces.utility import IdentityInterface, Function\n",
    "from nipype.interfaces.io import SelectFiles, DataSink, DataGrabber\n",
    "from nipype.interfaces.fsl.preprocess import FLIRT, SUSAN\n",
    "from nipype.interfaces.fsl.utils import Merge, ImageMeants\n",
    "from nipype.interfaces.fsl.model import GLM, Level1Design, FEATModel, FILMGLS\n",
    "from nipype.interfaces.fsl.maths import ApplyMask\n",
    "from nipype.algorithms.modelgen import SpecifyModel\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "# MATLAB setup - Specify path to current SPM and the MATLAB's default mode\n",
    "from nipype.interfaces.matlab import MatlabCommand\n",
    "MatlabCommand.set_default_paths('~/spm12/toolbox')\n",
    "MatlabCommand.set_default_matlab_cmd(\"matlab -nodesktop -nosplash\")\n",
    "\n",
    "# FSL set up- change default file output type\n",
    "from nipype.interfaces.fsl import FSLCommand\n",
    "FSLCommand.set_default_output_type('NIFTI')\n",
    "\n",
    "# Set study variables\n",
    "#analysis_home = '/Users/catcamacho/Box/LNCD_rewards_connectivity'\n",
    "analysis_home = '/Volumes/Zeus/Cat'\n",
    "#raw_dir = analysis_home + '/subjs'\n",
    "raw_dir = '/Volumes/Phillips/bars/APWF_bars/subjs'\n",
    "preproc_dir = analysis_home + '/proc/preprocessing'\n",
    "firstlevel_dir = analysis_home + '/proc/firstlevel'\n",
    "secondlevel_dir = analysis_home + '/proc/secondlevel'\n",
    "workflow_dir = analysis_home + '/workflows'\n",
    "template_dir = analysis_home + '/templates'\n",
    "\n",
    "MNI_template = template_dir + '/MNI152_T1_3mm_brain.nii'\n",
    "MNI_mask = template_dir + '/MNI152_T1_3mm_mask.nii'\n",
    "\n",
    "#pull subject info to iter over\n",
    "subject_info = DataFrame.from_csv(analysis_home + '/misc/subjs.csv')\n",
    "subjects_list = subject_info['SubjID'].tolist()\n",
    "timepoints = subject_info['Timepoint'].tolist()\n",
    "\n",
    "#subjects_list = [10766]\n",
    "#timepoints = [1]\n",
    "\n",
    "# Seeds list- based on aseg segmentation\n",
    "L_amyg = 18\n",
    "R_amyg = 54\n",
    "\n",
    "seeds = [L_amyg, R_amyg]\n",
    "seed_names = ['L_amyg','R_amyg']\n",
    "\n",
    "TR = 1.5\n",
    "\n",
    "conditions = ['punish','reward','neutral']\n",
    "motion_thresh = 0.9 #in millimeters for trial-wise exclusion of data\n",
    "BOLD_window = 8 # in TRs\n",
    "smoothing_kernel = 6\n",
    "min_trials_for_usability = 20 #per condition, selected based on Paulsen 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data handling nodes\n",
    "infosource = Node(IdentityInterface(fields=['subjid','timepoint']), \n",
    "                  name='infosource')\n",
    "infosource.iterables = [('subjid', subjects_list),('timepoint', timepoints)]\n",
    "infosource.synchronize = True\n",
    "\n",
    "#grab timing files\n",
    "time_template = {'timing':raw_dir + '/%s/%d_*/timing/*score_timing.txt'}\n",
    "timegrabber = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = raw_dir + '/%d/%d_*/timing/*score_timing.txt',\n",
    "                               field_template = time_template,\n",
    "                               base_directory=raw_dir,\n",
    "                               infields=['subjid','timepoint'], \n",
    "                               template_args={'timing':[['subjid','timepoint']]}), \n",
    "                   name='timegrabber')\n",
    "\n",
    "# Grab niftis\n",
    "template = {'struct': preproc_dir + '/preproc_anat/{subjid}_t{timepoint}/reoriented_anat.nii',\n",
    "            'func': preproc_dir + '/preproc_func/{subjid}_t{timepoint}/func_filtered.nii',\n",
    "            'segmentation': preproc_dir + '/aseg/{subjid}_t{timepoint}/reoriented_aseg.nii',\n",
    "            'motion': preproc_dir + '/motion_params/{subjid}_t{timepoint}/allmotion.txt'}\n",
    "datasource = Node(SelectFiles(template), \n",
    "                  name = 'datasource')\n",
    "\n",
    "#sink important data\n",
    "substitutions = [('_subjid_', ''),\n",
    "                 ('_timepoint_','_t'), \n",
    "                 ('_condition_',''),\n",
    "                 ('_max_18_min_18','L_amyg'), \n",
    "                 ('_max_54_min_54','R_amyg')]\n",
    "datasink = Node(DataSink(substitutions=substitutions, \n",
    "                         base_directory=firstlevel_dir,\n",
    "                         container=firstlevel_dir), \n",
    "                name='datasink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract timing for Beta Series Method- mark trials as high and low motion\n",
    "def timing_bars(run_timing_list, condition, motion, motion_thresh, BOLD_window):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from pandas import DataFrame,Series,read_table,concat\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    \n",
    "    # Import and organize motion data\n",
    "    motion_df = read_table(motion,delim_whitespace=True,header=None)\n",
    "    mean_translation = motion_df[[3,4,5]].mean(axis=1)\n",
    "    \n",
    "    # Create full task dataframe\n",
    "    run_timing_list = sorted(run_timing_list)\n",
    "    dfs = [ read_table(i,delim_whitespace=True) for i in run_timing_list ]\n",
    "    k=1\n",
    "    for df in dfs:\n",
    "        df.loc[:,'runNum'] = Series(k, index = df.index)\n",
    "        df.loc[:,'time_hyp'] = (k-1)*453 + df.loc[:,'time_hyp']\n",
    "        df.loc[:,'trial'] = (k*100) + df.loc[:,'trial']\n",
    "        k = k+1\n",
    "    df_full = concat(dfs,ignore_index=True)\n",
    "    df_full = df_full.sort(['runNum','time_hyp'], ascending=[1,1])\n",
    "    df_full.loc[:,'motion'] = mean_translation\n",
    "    \n",
    "    # Sort out trials that are both complete and received a response\n",
    "    df_responded = df_full[df_full.loc[:,'Count'] == 1]\n",
    "    df_responded = df_responded[df_responded.loc[:,'catch']==0]\n",
    "\n",
    "    # Sort out trial onsets for the condition of interest\n",
    "    df_condition = df_responded[df_responded.loc[:,'cond']==condition]\n",
    "    df_condition = df_condition[df_condition.loc[:,'stim']=='cue']\n",
    "    \n",
    "    # Add additional label to the trials with high motion\n",
    "    df_condition.loc[:,'mot_cat'] = Series('low',index=df_condition.index)\n",
    "    for index, row in df_condition.iterrows():\n",
    "        hrf_length = index+BOLD_window\n",
    "        trial_motion = df_full.iloc[index:hrf_length,8]\n",
    "        excess_vols = (trial_motion >= motion_thresh) + (trial_motion <= (-1*motion_thresh))\n",
    "        if sum(excess_vols) >= 4:\n",
    "            df_condition.loc[index,'mot_cat'] = 'high'    \n",
    "    \n",
    "    lowmotion = df_condition[df_condition.loc[:, 'mot_cat'] == 'low']\n",
    "    highmotion = df_condition[df_condition.loc[:, 'mot_cat'] == 'high']\n",
    "    \n",
    "    # create onsets list\n",
    "    lm_onsets = lowmotion['time_hyp'].tolist()\n",
    "    hm_onsets = highmotion['time_hyp'].tolist()\n",
    "    lm_onsets_list = [[o] for o in lm_onsets]\n",
    "    hm_onsets_list = [[p] for p in hm_onsets]\n",
    "    onsets = lm_onsets_list + hm_onsets_list\n",
    "    \n",
    "    # create trial names\n",
    "    lm_trialnames = [(condition + '_lm' + str(h)) for h in range(0,len(lm_onsets_list))]\n",
    "    hm_trialnames = [(condition + '_hm' + str(i)) for i in range(0,len(hm_onsets_list))]\n",
    "    trialNames = lm_trialnames + hm_trialnames\n",
    "    \n",
    "    #make bunch file\n",
    "    timing_bunch = []\n",
    "    timing_bunch.insert(0,Bunch(conditions=trialNames,\n",
    "                                onsets=onsets,\n",
    "                                durations=[[4.5] for s in trialNames],\n",
    "                                amplitudes=None,\n",
    "                                tmod=None,\n",
    "                                pmod=None,\n",
    "                                regressor_names=None,\n",
    "                                regressors=None))\n",
    "    return(timing_bunch)\n",
    "\n",
    "# Function to create contrast lists from a bunch file\n",
    "def beta_contrasts(timing_bunch):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from numpy import zeros\n",
    "    \n",
    "    conditions_names = timing_bunch[0].conditions\n",
    "    \n",
    "    # Make the contrast vectors for each trial\n",
    "    boolean_con_lists = []\n",
    "    num_cons = len(conditions_names)\n",
    "    for i in range(0,num_cons):\n",
    "        boo = zeros(num_cons)\n",
    "        boo[i] = 1\n",
    "        boolean_con_lists.append(list(boo))\n",
    "    \n",
    "    # Create the list of lists for the full contrast info\n",
    "    contrasts_list = []\n",
    "    for a in range(0,num_cons):\n",
    "        con = [conditions_names[a], 'T', conditions_names, boolean_con_lists[a]]\n",
    "        contrasts_list.append(con)\n",
    "        \n",
    "    return(contrasts_list)\n",
    "\n",
    "# Function to write the beta series trial names to a text file\n",
    "def beta_list(timing_bunch):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    from nipype.interfaces.base import Bunch\n",
    "    from os.path import abspath\n",
    "    \n",
    "    conditions_names = timing_bunch[0].conditions\n",
    "    filename = open('betanames.txt','w')\n",
    "    for line in conditions_names:\n",
    "        filename.write(line + '\\n')\n",
    "    \n",
    "    filename.close()\n",
    "    condition_file = abspath('betanames.txt')\n",
    "    \n",
    "    return(condition_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract timing\n",
    "pull_timing = Node(Function(input_names=['run_timing_list','condition',\n",
    "                                         'motion','motion_thresh','BOLD_window'],\n",
    "                            output_names=['timing_bunch'],\n",
    "                            function=timing_bars), name='pull_timing')\n",
    "pull_timing.inputs.BOLD_window = BOLD_window\n",
    "pull_timing.inputs.motion_thresh = motion_thresh\n",
    "pull_timing.iterables = [('condition',conditions)]\n",
    "\n",
    "# create the list of T-contrasts\n",
    "define_contrasts = Node(Function(input_names=['timing_bunch'], \n",
    "                                 output_names = ['contrasts_list'], \n",
    "                                 function=beta_contrasts),\n",
    "                        name = 'define_contrasts')\n",
    "\n",
    "# Save the beta series list name for later organization\n",
    "save_beta_list = Node(Function(input_names=['timing_bunch'], \n",
    "                               output_names=['condition_file'], \n",
    "                               function=beta_list), \n",
    "                      name='save_beta_list')\n",
    "\n",
    "# Specify FSL model - input bunch file called subject_info\n",
    "modelspec = Node(SpecifyModel(time_repetition=TR, \n",
    "                              input_units='secs',\n",
    "                              high_pass_filter_cutoff=0),\n",
    "                 name='modelspec')\n",
    "\n",
    "# Generate a level 1 design\n",
    "level1design = Node(Level1Design(bases={'dgamma':{'derivs': False}},\n",
    "                                 interscan_interval=TR, # the TR\n",
    "                                 model_serial_correlations=True), \n",
    "                    name='level1design')\n",
    "\n",
    "# Estimate Level 1\n",
    "generateModel = Node(FEATModel(), \n",
    "                     name='generateModel')\n",
    "\n",
    "# Run GLM\n",
    "extract_betas = Node(FILMGLS(threshold=-1000, \n",
    "                             fit_armodel=False,\n",
    "                             smooth_autocorr=False,\n",
    "                             full_data=True), \n",
    "                     name='extract_betas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect the workflow\n",
    "betaseriesflow = Workflow(name='betaseriesflow')\n",
    "betaseriesflow.connect([(infosource, datasource,[('subjid','subjid')]),\n",
    "                        (infosource, datasource,[('timepoint','timepoint')]),\n",
    "                        (infosource, timegrabber,[('subjid','subjid')]),\n",
    "                        (infosource, timegrabber,[('timepoint','timepoint')]),\n",
    "                        (timegrabber, pull_timing, [('timing','run_timing_list')]),\n",
    "                        (datasource, pull_timing, [('motion','motion')]),\n",
    "                        (pull_timing, modelspec, [('timing_bunch','subject_info')]),\n",
    "                        (datasource, modelspec, [('func','functional_runs')]),\n",
    "                        (pull_timing, define_contrasts, [('timing_bunch','timing_bunch')]),\n",
    "                        (define_contrasts, level1design, [('contrasts_list','contrasts')]),\n",
    "                        (modelspec, level1design, [('session_info','session_info')]),\n",
    "                        (level1design,generateModel, [('ev_files','ev_files')]),\n",
    "                        (level1design,generateModel, [('fsf_files','fsf_file')]),\n",
    "                        (generateModel,extract_betas, [('design_file','design_file')]),\n",
    "                        (generateModel,extract_betas, [('con_file','tcon_file')]),\n",
    "                        (datasource,extract_betas, [('func','in_file')]),\n",
    "                        (pull_timing,save_beta_list, [('timing_bunch','timing_bunch')]),\n",
    "                        \n",
    "                        (save_beta_list,datasink, [('condition_file','condition_file')]),\n",
    "                        (extract_betas,datasink,[('copes','copes')]),\n",
    "                        (extract_betas,datasink,[('param_estimates','betas')]),\n",
    "                        (extract_betas,datasink,[('tstats','tstats')]),\n",
    "                        (generateModel,datasink,[('design_image','design_image')])\n",
    "                       ])\n",
    "betaseriesflow.base_dir = workflow_dir\n",
    "betaseriesflow.write_graph(graph2use='flat')\n",
    "#betaseriesflow.run('MultiProc', plugin_args={'n_procs': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Functions for connectivity analysis\n",
    "\n",
    "# Brightness threshold should be 0.75 * the contrast between the median brain intensity and the background\n",
    "def calc_brightness_threshold(func_vol):\n",
    "    import nibabel as nib\n",
    "    from numpy import median, where\n",
    "    \n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    \n",
    "    func_nifti1 = nib.load(func_vol)\n",
    "    func_data = func_nifti1.get_data()\n",
    "    func_data = func_data.astype(float)\n",
    "    \n",
    "    brain_values = where(func_data > 0)\n",
    "    median_thresh = median(brain_values)\n",
    "    brightness_threshold = 0.75 * median_thresh\n",
    "    return(brightness_threshold)\n",
    "\n",
    "def sort_beta_series(betas, condition, condition_key):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import dirname\n",
    "    \n",
    "    cond_betas = []\n",
    "    for s in betas:\n",
    "        if condition in s:\n",
    "            cond_betas.append(s)\n",
    "\n",
    "    num_pes = len(cond_betas)\n",
    "    beta_dir = dirname(cond_betas[0])\n",
    "\n",
    "    for t in condition_key:\n",
    "        if condition in t:\n",
    "            text_file = open(t, 'r')\n",
    "            cond_keys = text_file.read().splitlines()\n",
    "            text_file.close()\n",
    "\n",
    "    beta_list = []\n",
    "    for u in range(0,len(cond_keys)):\n",
    "        if 'lm' in cond_keys[u]:\n",
    "            beta_list.append(beta_dir + '/pe' + str(u+1) + '.nii')\n",
    "\n",
    "    return(beta_list)\n",
    "\n",
    "def check_beta_power(beta_list, ntrial_min):\n",
    "    from nipype import config, logging\n",
    "    config.enable_debug_mode()\n",
    "    logging.update_logging(config)\n",
    "    from os.path import abspath\n",
    "        \n",
    "    if len(beta_list) < ntrial_min:\n",
    "        f= open('FAIL.txt','w')\n",
    "        f.write('subject only has ' + str(len(beta_list)) + \n",
    "                ' usable trials, which is fewer than the minimum ' + str(ntrial_min))\n",
    "        f.close()\n",
    "        power_det = abspath('FAIL.txt')\n",
    "    else:\n",
    "        f= open('pass.txt','w')\n",
    "        f.write('subject has ' + str(len(beta_list)) + ' usable trials.')\n",
    "        f.close()\n",
    "        power_det = abspath('pass.txt')\n",
    "    \n",
    "    return(power_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Connectivity nodes\n",
    "\n",
    "# grab files\n",
    "beta_template = {'betas':firstlevel_dir + '/betas/%s_t%d/*/pe*.nii'}\n",
    "beta_grabber = Node(DataGrabber(sort_filelist=True,\n",
    "                               template = firstlevel_dir + '/betas/%s_t%d/*/pe*.nii',\n",
    "                               field_template = beta_template,\n",
    "                               base_directory=firstlevel_dir,\n",
    "                               infields=['subjid','timepoint'], \n",
    "                               template_args={'betas':[['subjid','timepoint']]}), \n",
    "                    name='beta_grabber')\n",
    "\n",
    "condtemplate = {'condition_key':firstlevel_dir + '/condition_file/%s_t%d/*/betanames.txt'}\n",
    "conditionlist_grabber = Node(DataGrabber(template = firstlevel_dir + '/condition_file/%s_t%d/*/betanames.txt',\n",
    "                                         sort_filelist=True,\n",
    "                                         field_template = condtemplate,\n",
    "                                         base_directory=firstlevel_dir,\n",
    "                                         infields=['subjid','timepoint'],\n",
    "                                         template_args={'condition_key':[['subjid','timepoint']]}), \n",
    "                             name='conditionlist_grabber')\n",
    "\n",
    "sort_series = Node(Function(input_names=['betas','condition','condition_key'],\n",
    "                            output_names=['beta_list'],\n",
    "                            function=sort_beta_series), \n",
    "                   name='sort_series')\n",
    "sort_series.iterables = [('condition',conditions)]\n",
    "\n",
    "# check power by counting how many usable low-motion trials are being included\n",
    "check_power = Node(Function(input_names=['beta_list','ntrial_min'],\n",
    "                            output_names=['power_det'], \n",
    "                            function=check_beta_power), \n",
    "                            name='check_power')\n",
    "check_power.inputs.ntrial_min = min_trials_for_usability\n",
    "\n",
    "# Merge PEs to 1 4D volume per condition\n",
    "merge_series = Node(Merge(dimension='t'), \n",
    "                    name='merge_series')\n",
    "\n",
    "# Make ROI masks\n",
    "ROI_mask = Node(Binarize(out_type='nii'), \n",
    "                name='ROI_mask')\n",
    "ROI_mask.iterables = [('min',seeds),('max',seeds)]\n",
    "ROI_mask.synchronize = True\n",
    "\n",
    "# Extract ROI beta series: input mask and in_file, output out_file\n",
    "extract_ROI_betas = Node(ImageMeants(), name='extract_ROI_betas')\n",
    "\n",
    "# Extract beta connectivity\n",
    "beta_series_conn = Node(GLM(out_file='betas.nii',\n",
    "                            out_cope='cope.nii'), \n",
    "                        name='beta_series_conn')\n",
    "\n",
    "# Calculate brightness threshold\n",
    "calc_bright_thresh = Node(Function(input_names=['func_vol'],\n",
    "                                   output_names=['brightness_threshold'],\n",
    "                                   function=calc_brightness_threshold), \n",
    "                          name='calc_bright_thresh')\n",
    "\n",
    "# Smooth parameter estimates- input brightness_threshold and in_file; output smoothed_file\n",
    "smooth = Node(SUSAN(fwhm=smoothing_kernel), \n",
    "              name='smooth')\n",
    "\n",
    "# Register to MNI space\n",
    "reg_anat2mni = Node(FLIRT(out_matrix_file='transform.mat',\n",
    "                          reference=MNI_template),\n",
    "                    name='reg_anat2mni')\n",
    "\n",
    "reg_pe2mni = Node(FLIRT(apply_xfm=True,\n",
    "                        reference=MNI_template), \n",
    "                  name='reg_pe2mni')\n",
    "\n",
    "# Apply a stricter mask now that the subject is in MNI space (it was really liberal before)\n",
    "applyMNImask = Node(ApplyMask(mask_file=MNI_mask), name ='applyMNImask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connectivityflow = Workflow(name='connectivityflow')\n",
    "connectivityflow.connect([(infosource, datasource, [('subjid','subjid')]),\n",
    "                          (infosource, datasource, [('timepoint','timepoint')]),\n",
    "                          (datasource, ROI_mask, [('segmentation','in_file')]),\n",
    "                          (ROI_mask, extract_ROI_betas, [('binary_file','mask')]),\n",
    "                          (extract_ROI_betas, beta_series_conn, [('out_file','design')]),\n",
    "                          \n",
    "                          (infosource, beta_grabber,[('subjid','subjid')]),\n",
    "                          (infosource, beta_grabber,[('timepoint','timepoint')]),\n",
    "                          (infosource, conditionlist_grabber,[('subjid','subjid')]),\n",
    "                          (infosource, conditionlist_grabber,[('timepoint','timepoint')]),\n",
    "                          (beta_grabber, sort_series, [('betas','betas')]),\n",
    "                          (conditionlist_grabber, sort_series, [('condition_key','condition_key')]),\n",
    "                          (sort_series, check_power, [('beta_list','beta_list')]),\n",
    "                          (sort_series, merge_series, [('beta_list','in_files')]),\n",
    "                          (merge_series, extract_ROI_betas, [('merged_file','in_file')]),\n",
    "                          (merge_series, beta_series_conn, [('merged_file','in_file')]),\n",
    "                          \n",
    "                          (datasource, reg_anat2mni, [('struct','in_file')]),\n",
    "                          (reg_anat2mni, reg_pe2mni, [('out_matrix_file','in_matrix_file')]),\n",
    "                          (beta_series_conn, reg_pe2mni, [('out_file','in_file')]),\n",
    "                          (reg_pe2mni, calc_bright_thresh, [('out_file','func_vol')]),\n",
    "                          (calc_bright_thresh, smooth, [('brightness_threshold','brightness_threshold')]),\n",
    "                          (reg_pe2mni, smooth, [('out_file','in_file')]),\n",
    "                          (smooth, applyMNImask, [('smoothed_file','in_file')]),\n",
    "                          \n",
    "                          (ROI_mask, datasink, [('binary_file','seed_masks')]),\n",
    "                          (check_power, datasink, [('power_det','power_check_results')]),\n",
    "                          (beta_series_conn, datasink, [('out_file','conn_beta_map')]),\n",
    "                          (beta_series_conn, datasink, [('out_p','conn_pval_map')]),\n",
    "                          (beta_series_conn, datasink, [('out_cope','conn_cope')]),\n",
    "                          (applyMNImask, datasink, [('out_file','smoothedMNI_conn_beta')]),\n",
    "                          (reg_anat2mni, datasink, [('out_file','MNIwarp_anat')])\n",
    "                         ])\n",
    "connectivityflow.base_dir = workflow_dir\n",
    "connectivityflow.write_graph(graph2use='flat')\n",
    "connectivityflow.run('MultiProc', plugin_args={'n_procs':30})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
